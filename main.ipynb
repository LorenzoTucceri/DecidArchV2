{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-16T13:18:51.049432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "class DecidArchAssistant:\n",
    "    def __init__(self, configuration, system_template=None):\n",
    "        self.configuration = configuration\n",
    "        self.llm = self._initialize_llm()\n",
    "        self.system_template = system_template\n",
    "\n",
    "        # Examples for Few Shot Learning\n",
    "        examples = [\n",
    "            {\n",
    "                \"question\": \"how is the weather\",\n",
    "                \"answer\": \"The weather is fine.\"\n",
    "            },\n",
    "            {\n",
    "                \"question\": \"what is the time\",\n",
    "                \"answer\": \"The current time is 10 AM.\"\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        # Create example prompts in the format required by FewShotPromptTemplate\n",
    "        example_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\", \"answer\"], \n",
    "            template=\"Question: {question}\\n{answer}\"\n",
    "        )\n",
    "    \n",
    "        self.few_shot_template = FewShotPromptTemplate(\n",
    "            examples=examples,\n",
    "            example_prompt=example_prompt,\n",
    "            suffix=\"Consider the following comments about a design decision and make suggestions based on stakeholder concerns:\",\n",
    "            input_variables=[\"commento\"]    \n",
    "        )\n",
    "\n",
    "        self.prompt = ChatPromptTemplate(\n",
    "            messages=[\n",
    "                MessagesPlaceholder(\"few_shot_examples\"),\n",
    "                HumanMessagePromptTemplate.from_template(\"{user_input}\" + \"\\n\" + \"DecidArch: \"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.conversation = LLMChain(\n",
    "            prompt=self.prompt,\n",
    "            llm=self.llm,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "    def _initialize_llm(self):\n",
    "        # Initialize the language model here\n",
    "        return Ollama()  # Adjust the initialization as per the actual requirements of Ollama\n",
    "    \n",
    "    def provide_suggestions(self, comment):\n",
    "        # Prepare few-shot examples\n",
    "        formatted_example = self.few_shot_template.format(commento=comment)\n",
    "        \n",
    "        # Create a list of example dictionaries\n",
    "        few_shot_examples = [{\"role\": \"assistant\", \"content\": formatted_example}]\n",
    "    \n",
    "        # Use the conversation chain to get a response\n",
    "        response = self.conversation.run({\"user_input\": comment, \"few_shot_examples\": few_shot_examples})\n",
    "        return response\n",
    "\n",
    "# Configuration class definition\n",
    "class Configuration:\n",
    "    pass\n",
    "\n",
    "# Example usage of the class\n",
    "configuration = Configuration()\n",
    "assistant = DecidArchAssistant(configuration)\n",
    "\n",
    "# Example comments\n",
    "comments = [\n",
    "    \"I think the priority should be multiplied with the score instead of ignored when summing the final score.\",\n",
    "    \"Yes, but when the + and - values were already given, we just looked at those.\"\n",
    "]\n",
    "\n",
    "# Process each comment and print the suggestions\n",
    "for comment in comments:\n",
    "    suggestion = assistant.provide_suggestions(comment)\n",
    "    print(suggestion)"
   ],
   "id": "9964f22dded8ae64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mAI: Question: how is the weather\n",
      "The weather is fine.\n",
      "\n",
      "Question: what is the time\n",
      "The current time is 10 AM.\n",
      "\n",
      "Consider the following comments about a design decision and make suggestions based on stakeholder concerns:\n",
      "Human: I think the priority should be multiplied with the score instead of ignored when summing the final score.\n",
      "DecidArch: \u001B[0m\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a13ce40a9e4a3dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
